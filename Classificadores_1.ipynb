{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453b8679",
   "metadata": {},
   "source": [
    "# Questionário 3\n",
    "\n",
    "### Leitura de Dados\n",
    "\n",
    "Hugo de Oliveira Borges  nUSP: $11915202$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "8f58c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "46219790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de atributos: Número de linhas: 310  colunas:  7\n",
      "['Hernia' 'Spondylolisthesis' 'Normal']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.250200</td>\n",
       "      <td>13.921907</td>\n",
       "      <td>25.124950</td>\n",
       "      <td>26.328293</td>\n",
       "      <td>130.327871</td>\n",
       "      <td>2.230652</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53.432928</td>\n",
       "      <td>15.864336</td>\n",
       "      <td>37.165934</td>\n",
       "      <td>37.568592</td>\n",
       "      <td>120.567523</td>\n",
       "      <td>5.988551</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45.366754</td>\n",
       "      <td>10.755611</td>\n",
       "      <td>29.038349</td>\n",
       "      <td>34.611142</td>\n",
       "      <td>117.270067</td>\n",
       "      <td>-10.675871</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43.790190</td>\n",
       "      <td>13.533753</td>\n",
       "      <td>42.690814</td>\n",
       "      <td>30.256437</td>\n",
       "      <td>125.002893</td>\n",
       "      <td>13.289018</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36.686353</td>\n",
       "      <td>5.010884</td>\n",
       "      <td>41.948751</td>\n",
       "      <td>31.675469</td>\n",
       "      <td>84.241415</td>\n",
       "      <td>0.664437</td>\n",
       "      <td>Hernia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
       "0         63.027817    22.552586              39.609117     40.475232   \n",
       "1         39.056951    10.060991              25.015378     28.995960   \n",
       "2         68.832021    22.218482              50.092194     46.613539   \n",
       "3         69.297008    24.652878              44.311238     44.644130   \n",
       "4         49.712859     9.652075              28.317406     40.060784   \n",
       "5         40.250200    13.921907              25.124950     26.328293   \n",
       "6         53.432928    15.864336              37.165934     37.568592   \n",
       "7         45.366754    10.755611              29.038349     34.611142   \n",
       "8         43.790190    13.533753              42.690814     30.256437   \n",
       "9         36.686353     5.010884              41.948751     31.675469   \n",
       "\n",
       "   pelvic_radius  degree_spondylolisthesis   class  \n",
       "0      98.672917                 -0.254400  Hernia  \n",
       "1     114.405425                  4.564259  Hernia  \n",
       "2     105.985135                 -3.530317  Hernia  \n",
       "3     101.868495                 11.211523  Hernia  \n",
       "4     108.168725                  7.918501  Hernia  \n",
       "5     130.327871                  2.230652  Hernia  \n",
       "6     120.567523                  5.988551  Hernia  \n",
       "7     117.270067                -10.675871  Hernia  \n",
       "8     125.002893                 13.289018  Hernia  \n",
       "9      84.241415                  0.664437  Hernia  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42) # define the seed (important to reproduce the results)\n",
    "\n",
    "data = pd.read_csv('../data/vertebralcolumn-3C.csv', header=(0))\n",
    "\n",
    "data = data.dropna(axis='rows') #remove NaN\n",
    "\n",
    "# armazena os nomes das classes\n",
    "nrow, ncol = data.shape\n",
    "print(\"Matriz de atributos: Número de linhas:\", nrow, \" colunas: \", ncol)\n",
    "attributes = list(data.columns)\n",
    "\n",
    "print(data['class'].unique())\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35ef52",
   "metadata": {},
   "source": [
    "Como queremos escolher o melhor classificador, iremos converter para a Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "a35d523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()\n",
    "nrow,ncol = data.shape\n",
    "y = data[:,-1]\n",
    "X = data[:,0:ncol-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "02030113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media:  [ 1.03143300e-16 -4.58414668e-17 -2.97969534e-16 -6.87622002e-17\n",
      "  3.49541185e-16 -6.87622002e-17]\n",
      "Desvio Padrão:  [1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print('Media: ', np.mean(X, axis=0))\n",
    "print('Desvio Padrão: ', np.std(X, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f73f7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar os conjuntos de treinamento e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "p = 0.8 # fracao de elementos no conjunto de treinamento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)\n",
    "\n",
    "# definindo as classes\n",
    "classes = np.unique(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b84d52",
   "metadata": {},
   "source": [
    "### 1 - Considerando a base de dados vertebralcolumn-2C.csv, encontre o melhor classificador dentre os métodos classificador Bayesiano, classificador Bayesino não paramétrico e Naive Bayes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a5f22",
   "metadata": {},
   "source": [
    "### O primeiro caso será para o classificador **Paramétrico**\n",
    "\n",
    "Como o conjunto de treinamento e de teste estão separados, será calculado a média e o desvio padrão dos atributos de classe e em seguida teremos a classificação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "3e2d5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "#matrix to store the probabilities\n",
    "P = pd.DataFrame(data=np.zeros((X_test.shape[0], len(classes))), columns = classes) \n",
    "\n",
    "Pc = np.zeros(len(classes)) #fraction of elements in each class\n",
    "\n",
    "\n",
    "for i in np.arange(0, len(classes)):\n",
    "    elements = np.array(np.where(y_train == classes[i]))\n",
    "    Pc[i] = elements.shape[1]/len(y_train) #Calcular a chance de pertencer\n",
    "    Z = X_train[elements,:][0].astype(float)\n",
    "    m = np.mean(Z, axis = 0)\n",
    "    cv = np.cov(np.transpose(Z))\n",
    "    \n",
    "    for j in np.arange(0,X_test.shape[0]):\n",
    "        x = X_test[j,:]\n",
    "        pj = multivariate_normal.pdf(x, mean=m, cov=cv, allow_singular=True)\n",
    "        P.iloc[j, i] = pj * Pc[i]\n",
    "#print(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "e5d4adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "#np.array(test_x.shape[0], dtype=str)\n",
    "for i in np.arange(0, X_test.shape[0]):\n",
    "    c = np.argmax(np.array(P.iloc[[i]])) #Coluna que apresenta a maior probabilidade\n",
    "    y_pred.append(classes[c])\n",
    "    \n",
    "y_pred = np.array(y_pred)\n",
    "y_test = np.array(y_test)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "162dc865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7903225806451613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91757146",
   "metadata": {},
   "source": [
    "### Agora para o caso **não paramétrico**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "6beb38ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media:  [ 1.03143300e-16 -4.58414668e-17 -2.97969534e-16 -6.87622002e-17\n",
      "  3.49541185e-16 -6.87622002e-17]\n",
      "Desvio Padrão:  [1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "data = pd.read_csv('../data/vertebralcolumn-3C.csv', header=(0))\n",
    "\n",
    "classes = np.array(pd.unique(data[data.columns[-1]]), dtype=str)  \n",
    "\n",
    "# Converte para matriz e vetor do numpy\n",
    "data = data.to_numpy()\n",
    "nrow,ncol = data.shape\n",
    "y = data[:,-1]\n",
    "X = data[:,0:ncol-1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print('Media: ', np.mean(X, axis=0))\n",
    "print('Desvio Padrão: ', np.std(X, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "618917c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia: 0.8387096774193549\n"
     ]
    }
   ],
   "source": [
    "# Seleciona os conjuntos de treinamento e teste\n",
    "p = 0.8 # fraction of elements in the training set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)\n",
    "\n",
    "# Matriz que armazena as probabilidades para cada classe\n",
    "P = pd.DataFrame(data=np.zeros((x_test.shape[0], len(classes))), columns = classes) \n",
    "Pc = np.zeros(len(classes)) # Armazena a fracao de elementos em cada classe\n",
    "h = 2\n",
    "\n",
    "for i in np.arange(0, len(classes)): # Para cada classe\n",
    "\n",
    "    elements = tuple(np.where(y_train == classes[i])) # elmentos na classe i\n",
    "\n",
    "    Pc[i] = len(elements)/len(y_train) # Probabilidade pertencer a classe i\n",
    "\n",
    "    Z = x_train[elements,:][0].astype(float) # Elementos no conjunto de treinamento\n",
    "\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=h).fit(Z) #estimativa\n",
    "\n",
    "    for j in np.arange(0,x_test.shape[0]): # para cada observacao no conjunto de teste\n",
    "\n",
    "        x = x_test[j,:]\n",
    "        x = x.reshape((1,len(x))) #formato aceitável para a função\n",
    "        \n",
    "        # calcula a probabilidade pertencer a cada classe\n",
    "        pj = np.exp(kde.score_samples(x)) #log, então precisa calcular o exponencial\n",
    "        P.iloc[j, i] = pj * Pc[i]\n",
    "        \n",
    "y_pred = [] # Vetor com as classes preditas\n",
    "for i in np.arange(0, x_test.shape[0]):\n",
    "    c = np.argmax(np.array(P.iloc[[i]]))\n",
    "    y_pred.append(classes[c])\n",
    "y_pred = np.array(y_pred, dtype=str)\n",
    "\n",
    "# calcula a acuracia\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Acuracia:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509ee30",
   "metadata": {},
   "source": [
    "### Por último **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "af0f470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de atributos: Número de linhas: 310  colunas:  7\n"
     ]
    }
   ],
   "source": [
    "random.seed(42) # define the seed (important to reproduce the results)\n",
    "\n",
    "data = pd.read_csv('../data/vertebralcolumn-3C.csv', header=(0))\n",
    "\n",
    "data = data.dropna(axis='rows') #remove NaN\n",
    "\n",
    "# armazena os nomes das classes\n",
    "nrow, ncol = data.shape\n",
    "print(\"Matriz de atributos: Número de linhas:\", nrow, \" colunas: \", ncol)\n",
    "attributes = list(data.columns)\n",
    "\n",
    "#data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "800a412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media:  [ 1.03143300e-16 -4.58414668e-17 -2.97969534e-16 -6.87622002e-17\n",
      "  3.49541185e-16 -6.87622002e-17]\n",
      "Desvio Padrão:  [1. 1. 1. 1. 1. 1.]\n",
      "(310, 7)\n"
     ]
    }
   ],
   "source": [
    "data = data.to_numpy()\n",
    "nrow,ncol = data.shape\n",
    "y = data[:,-1]\n",
    "X = data[:,0:ncol-1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print('Media: ', np.mean(X, axis=0))\n",
    "print('Desvio Padrão: ', np.std(X, axis=0))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "0300ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "p = 0.8 # fraction of elements in the training set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1963fc3",
   "metadata": {},
   "source": [
    "Classificação para atributos com **distribuição normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ff495510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.782258064516129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print('Accuracy: ', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38ce9f",
   "metadata": {},
   "source": [
    "Portanto, pela melhor acurácia, vemos que o melhor classificador para a base de dados é o **Naive Bayes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c10b6a",
   "metadata": {},
   "source": [
    "### 2 - Considerando a base de dados “winequality-red”, encontre o valor do hiperparâmetro $h$ que oferece a maior acurácia no Bayesino não-paramétrico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "887ec3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "data = pd.read_csv('../data/winequality-red.csv', header=(0))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4fa01",
   "metadata": {},
   "source": [
    "A diferença desse exercício para os outros é o formato das classes, nesse caso temos inteiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "3667d8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0.1: Acuracia = 0.5437\n",
      "h = 0.2: Acuracia = 0.6094\n",
      "h = 0.3: Acuracia = 0.6406\n",
      "h = 0.4: Acuracia = 0.6219\n",
      "h = 0.5: Acuracia = 0.6438\n",
      "h = 0.7: Acuracia = 0.6156\n",
      "h = 1.0: Acuracia = 0.5844\n",
      "h = 1.5: Acuracia = 0.5594\n",
      "h = 2.0: Acuracia = 0.5500\n",
      "\n",
      "Melhor h: 0.5 com acurácia: 0.6438\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "data = pd.read_csv('../data/winequality-red.csv', header=(0))\n",
    "classes = np.array(pd.unique(data[data.columns[-1]]))  \n",
    "\n",
    "# Converte para matriz e vetor do numpy\n",
    "data = data.to_numpy()\n",
    "nrow,ncol = data.shape\n",
    "y = data[:,-1]\n",
    "X = data[:,0:ncol-1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Seleciona os conjuntos de treinamento e teste\n",
    "p = 0.8\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)\n",
    "\n",
    "h_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 1.0, 1.5, 2.0]\n",
    "best_h = 0\n",
    "best_score = 0\n",
    "\n",
    "for h in h_values:\n",
    "    # Matriz que armazena as probabilidades para cada classe\n",
    "    P = pd.DataFrame(data=np.zeros((x_test.shape[0], len(classes))), columns = classes) \n",
    "    Pc = np.zeros(len(classes))\n",
    "\n",
    "    for i in np.arange(0, len(classes)):\n",
    "        elements = np.where(y_train == classes[i])[0]\n",
    "        Pc[i] = len(elements)/len(y_train)\n",
    "        \n",
    "        Z = x_train[elements, :]\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=h).fit(Z)\n",
    "\n",
    "        for j in np.arange(0,x_test.shape[0]):\n",
    "            x = x_test[j,:]\n",
    "            x = x.reshape((1,len(x)))\n",
    "            \n",
    "            pj = np.exp(kde.score_samples(x))\n",
    "            P.iloc[j, i] = pj * Pc[i]\n",
    "            \n",
    "    y_pred = []\n",
    "    for i in np.arange(0, x_test.shape[0]):\n",
    "        c = np.argmax(np.array(P.iloc[[i]]))\n",
    "        y_pred.append(classes[c])\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    print(f'h = {h}: Acuracia = {score:.4f}')\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_h = h\n",
    "\n",
    "print(f'\\nMelhor h: {best_h} com acurácia: {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40348a98",
   "metadata": {},
   "source": [
    "### 3 - Faça a classificação dos dados gerados artificialmente com o código abaixo. Compare os resultados para os métodos Naive Bayes, Classificador Bayesiano paramétrico e o classificador Bayesiano não-paramétrico (escolha um valor para h). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "e5a3b04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "data = datasets.make_moons(n_samples=n_samples, noise=.5, random_state=42)\n",
    "X = data[0]\n",
    "y = data[1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Selecionar os conjuntos de treinamento e teste\n",
    "p = 0.8 # fracao de elementos no conjunto de treinamento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)\n",
    "\n",
    "# definindo as classes\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "#matrix to store the probabilities\n",
    "P = pd.DataFrame(data=np.zeros((X_test.shape[0], len(classes))), columns = classes) \n",
    "\n",
    "Pc = np.zeros(len(classes)) #fraction of elements in each class\n",
    "\n",
    "for i in np.arange(0, len(classes)):\n",
    "    elements = np.array(np.where(y_train == classes[i]))\n",
    "    Pc[i] = elements.shape[1]/len(y_train) #Calcular a chance de pertencer\n",
    "    Z = X_train[elements,:][0].astype(float)\n",
    "    m = np.mean(Z, axis = 0)\n",
    "    cv = np.cov(np.transpose(Z))\n",
    "    \n",
    "    for j in np.arange(0,X_test.shape[0]):\n",
    "        x = X_test[j,:]\n",
    "        pj = multivariate_normal.pdf(x, mean=m, cov=cv, allow_singular=True)\n",
    "        P.iloc[j, i] = pj * Pc[i]\n",
    "#print(P)\n",
    "\n",
    "y_pred = []\n",
    "#np.array(test_x.shape[0], dtype=str)\n",
    "for i in np.arange(0, X_test.shape[0]):\n",
    "    c = np.argmax(np.array(P.iloc[[i]])) #Coluna que apresenta a maior probabilidade\n",
    "    y_pred.append(classes[c])\n",
    "    \n",
    "y_pred = np.array(y_pred)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Accuracy:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "2fe27608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia: 0.815\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "data = datasets.make_moons(n_samples=n_samples, noise=.5, random_state=42)\n",
    "X = data[0]\n",
    "y = data[1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Selecionar os conjuntos de treinamento e teste\n",
    "p = 0.8 # fraction of elements in the training set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size = p, random_state = 42)\n",
    "\n",
    "# definindo as classes\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "# Matriz que armazena as probabilidades para cada classe\n",
    "P = pd.DataFrame(data=np.zeros((x_test.shape[0], len(classes))), columns = classes) \n",
    "Pc = np.zeros(len(classes)) # Armazena a fracao de elementos em cada classe\n",
    "h = 0.4\n",
    "\n",
    "for i in np.arange(0, len(classes)): # Para cada classe\n",
    "\n",
    "    elements = np.where(y_train == classes[i])[0] # elementos na classe i\n",
    "\n",
    "    Pc[i] = len(elements)/len(y_train) # Probabilidade pertencer a classe i\n",
    "\n",
    "    Z = x_train[elements,:].astype(float) # Elementos no conjunto de treinamento\n",
    "\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=h).fit(Z) #estimativa\n",
    "\n",
    "    for j in np.arange(0,x_test.shape[0]): # para cada observacao no conjunto de teste\n",
    "\n",
    "        x = x_test[j,:]\n",
    "        x = x.reshape((1,len(x))) #formato aceitável para a função\n",
    "        \n",
    "        # calcula a probabilidade pertencer a cada classe\n",
    "        pj = np.exp(kde.score_samples(x)) #log, então precisa calcular o exponencial\n",
    "        P.iloc[j, i] = pj * Pc[i]\n",
    "        \n",
    "y_pred = [] # Vetor com as classes preditas\n",
    "for i in np.arange(0, x_test.shape[0]):\n",
    "    c = np.argmax(np.array(P.iloc[[i]]))\n",
    "    y_pred.append(classes[c])\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# calcula a acuracia\n",
    "score = accuracy_score(y_pred, y_test)\n",
    "print('Acuracia:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "8398ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.795\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "\n",
    "data = datasets.make_moons(n_samples=n_samples, noise=.5, random_state=42)\n",
    "X = data[0]\n",
    "y = data[1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "p = 0.2 # fraction of elements in the test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state = 42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print('Accuracy: ', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51c2a9",
   "metadata": {},
   "source": [
    "A acurácia em todos os modelos são muito semelhantes, a única diferença aconteceu no Bayesiano não paramétrico, quando é feito alteração no hipterparâmetro $h$.\n",
    "Isso pode ser causado tanto pela limitação do modelo quanto ao dataset ou até a simplicidade do dataset em relação aos modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
